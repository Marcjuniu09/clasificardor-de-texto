{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\marcj\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\marcj\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\marcj\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "C:\\Users\\marcj\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import zipfile\n",
    "import os\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.pipeline import Pipeline\n",
    "from time import sleep\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "import requests\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import urllib\n",
    "from urllib.request import urlretrieve \n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "\n",
    "import zipfile\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from sklearn.model_selection import ParameterGrid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lista = [\n",
    "\"20ng.csv.zip\", \n",
    "\"ACM.csv.zip\",\n",
    "\"CSTR.csv.zip\",\n",
    "\"Dmoz-Business.csv.zip\",\n",
    "\"Dmoz-Computers.csv.zip\",\n",
    "\"Dmoz-Health.csv.zip\",\n",
    "\"Dmoz-Science.csv.zip\",\n",
    "\"Dmoz-Sports.csv.zip\",\n",
    "\"Enron.csv.zip\",\n",
    "\"Hitech.csv.zip\",\n",
    "\"IrishEconomicSentiment.csv.zip\",\n",
    "\"LATimes.csv.zip\",\n",
    "\"NFS.csv.zip\",\n",
    "\"Opinosis.csv.zip\",\n",
    "\"PubMed_Cancer-2000.csv.zip\",\n",
    "\"PubMed_Cancer.csv.zip\",\n",
    "\"Re8.csv.zip\",\n",
    "\"Reuters-21578.csv.zip\",\n",
    "\"Reviews.csv.zip\",\n",
    "\"multi-domain-sentiment.csv.zip\",\n",
    "\"SpamAssassin.csv.zip\",\n",
    "\"SyskillWebert.csv.zip\",\n",
    "\"WebACE.csv.zip\",\n",
    "\"fbis.csv.zip\",\n",
    "\"industry-sector.csv.zip\",\n",
    "\"la1.mat.csv.zip\",\n",
    "\"la2.mat.csv.zip\",\n",
    "\"novo3.mat.csv.zip\",\n",
    "\"oh0.mat.csv.zip\",\n",
    "\"oh10.mat.csv.zip\",\n",
    "\"oh15.mat.csv.zip\",\n",
    "\"oh5.mat.csv.zip\",\n",
    "\"ohscal.mat.csv.zip\",\n",
    "\"ohsumed-400.csv.zip\",\n",
    "\"re0.mat.csv.zip\",\n",
    "\"re1.mat.csv.zip\",\n",
    "\"review_polarity.csv.zip\",\n",
    "\"tr11.mat.csv.zip\",\n",
    "\"tr12.mat.csv.zip\",\n",
    "\"tr21.mat.csv.zip\",\n",
    "\"tr23.mat.csv.zip\",\n",
    "\"tr31.mat.csv.zip\",\n",
    "\"tr41.mat.csv.zip\",\n",
    "\"tr45.mat.csv.zip\",\n",
    "\"trec7-3000.csv.zip\",\n",
    "\"wap.mat.csv.zip\",\n",
    "\"webkb.csv.zip\"]\n",
    "\n",
    "len(lista)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def dowload_data(lista):\n",
    "    for arquivo in lista:\n",
    "        url = f'https://github.com/ragero/text-collections/raw/master/Sequence_of_words_CSV/{arquivo}'\n",
    "        #baixa o arquivo e salvar na pasta data utilizando a biblioteca requests\n",
    "        r = requests.get(url)\n",
    "        with open(f'data/{arquivo}', 'wb') as f:\n",
    "            f.write(r.content)\n",
    "\"\"\"        with zipfile.ZipFile(f'data/{arquivo}', 'r') as zip_ref:\n",
    "            zip_ref.extractall('data')\n",
    "        \n",
    "        os.remove(f'data/{arquivo}')\n",
    "        \"\"\"\n",
    "\n",
    "def extract_zip_files(folder_path):\n",
    "    for file_name in os.listdir(folder_path):\n",
    "        file_path = os.path.join(folder_path, file_name)\n",
    "        if file_name.endswith('.zip'):\n",
    "            with zipfile.ZipFile(file_path, 'r') as zip_ref:\n",
    "                zip_ref.extractall(folder_path)\n",
    "            os.remove(file_path)\n",
    "        \n",
    "dowload_data(lista)\n",
    "extract_zip_files(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                   Text           Class\n",
      "0     subject manner similar termin graphic graphic ...  comp_windows_x\n",
      "1     standard cost offic subject name count bruce v...  comp_windows_x\n",
      "2     subject nasa nasa nasa nasa outland voic toolk...  comp_windows_x\n",
      "3     info subject server share friend friend close ...  comp_windows_x\n",
      "4     advantag helen helen code support subject citi...  comp_windows_x\n",
      "...                                                 ...             ...\n",
      "3895  jurisdict jurisdict jurisdict krakauer krakaue...         culture\n",
      "3896  ulihrach ulihrach ulihrach cheer cheer constru...         culture\n",
      "3897  oriol oriol affect affect confin confin tent t...         culture\n",
      "3898  sofa sofa sofa sofa sofa sofa refrain refrain ...         culture\n",
      "3899  titlehold titlehold verbal verbal construct co...         culture\n",
      "\n",
      "[273175 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "path = 'data/'\n",
    "\n",
    " \n",
    "files =  [file for file in os.listdir(path) if file.endswith('.csv')]\n",
    "#juntar todos os arquivos em um só\n",
    "df = pd.concat([pd.read_csv(path + file) for file in files])\n",
    "\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenization (df, column, new_column):\n",
    "    df[column] = df[column].astype(str)\n",
    "    df[new_column] = df[column].map(lambda x: word_tokenize(x))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = tokenization(df, 'Text', 'tokens')\n",
    "df.to_parquet('data/df.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Class</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>subject manner similar termin graphic graphic ...</td>\n",
       "      <td>comp_windows_x</td>\n",
       "      <td>[subject, manner, similar, termin, graphic, gr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>standard cost offic subject name count bruce v...</td>\n",
       "      <td>comp_windows_x</td>\n",
       "      <td>[standard, cost, offic, subject, name, count, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>subject nasa nasa nasa nasa outland voic toolk...</td>\n",
       "      <td>comp_windows_x</td>\n",
       "      <td>[subject, nasa, nasa, nasa, nasa, outland, voi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>info subject server share friend friend close ...</td>\n",
       "      <td>comp_windows_x</td>\n",
       "      <td>[info, subject, server, share, friend, friend,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>advantag helen helen code support subject citi...</td>\n",
       "      <td>comp_windows_x</td>\n",
       "      <td>[advantag, helen, helen, code, support, subjec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3895</th>\n",
       "      <td>jurisdict jurisdict jurisdict krakauer krakaue...</td>\n",
       "      <td>culture</td>\n",
       "      <td>[jurisdict, jurisdict, jurisdict, krakauer, kr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3896</th>\n",
       "      <td>ulihrach ulihrach ulihrach cheer cheer constru...</td>\n",
       "      <td>culture</td>\n",
       "      <td>[ulihrach, ulihrach, ulihrach, cheer, cheer, c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3897</th>\n",
       "      <td>oriol oriol affect affect confin confin tent t...</td>\n",
       "      <td>culture</td>\n",
       "      <td>[oriol, oriol, affect, affect, confin, confin,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3898</th>\n",
       "      <td>sofa sofa sofa sofa sofa sofa refrain refrain ...</td>\n",
       "      <td>culture</td>\n",
       "      <td>[sofa, sofa, sofa, sofa, sofa, sofa, refrain, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3899</th>\n",
       "      <td>titlehold titlehold verbal verbal construct co...</td>\n",
       "      <td>culture</td>\n",
       "      <td>[titlehold, titlehold, verbal, verbal, constru...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>273175 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   Text           Class  \\\n",
       "0     subject manner similar termin graphic graphic ...  comp_windows_x   \n",
       "1     standard cost offic subject name count bruce v...  comp_windows_x   \n",
       "2     subject nasa nasa nasa nasa outland voic toolk...  comp_windows_x   \n",
       "3     info subject server share friend friend close ...  comp_windows_x   \n",
       "4     advantag helen helen code support subject citi...  comp_windows_x   \n",
       "...                                                 ...             ...   \n",
       "3895  jurisdict jurisdict jurisdict krakauer krakaue...         culture   \n",
       "3896  ulihrach ulihrach ulihrach cheer cheer constru...         culture   \n",
       "3897  oriol oriol affect affect confin confin tent t...         culture   \n",
       "3898  sofa sofa sofa sofa sofa sofa refrain refrain ...         culture   \n",
       "3899  titlehold titlehold verbal verbal construct co...         culture   \n",
       "\n",
       "                                                 tokens  \n",
       "0     [subject, manner, similar, termin, graphic, gr...  \n",
       "1     [standard, cost, offic, subject, name, count, ...  \n",
       "2     [subject, nasa, nasa, nasa, nasa, outland, voi...  \n",
       "3     [info, subject, server, share, friend, friend,...  \n",
       "4     [advantag, helen, helen, code, support, subjec...  \n",
       "...                                                 ...  \n",
       "3895  [jurisdict, jurisdict, jurisdict, krakauer, kr...  \n",
       "3896  [ulihrach, ulihrach, ulihrach, cheer, cheer, c...  \n",
       "3897  [oriol, oriol, affect, affect, confin, confin,...  \n",
       "3898  [sofa, sofa, sofa, sofa, sofa, sofa, refrain, ...  \n",
       "3899  [titlehold, titlehold, verbal, verbal, constru...  \n",
       "\n",
       "[273175 rows x 3 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_parquet('data/df.parquet')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.series.Series'>\n"
     ]
    }
   ],
   "source": [
    "print(type(df['Class']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "Y = le.fit_transform(df['Class'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['100', '108', '11', '111', '118', '119', '12', '142', '161', '187',\n",
       "       '189', '202', '221', '240', '3', '3DTech', '4', '95', 'Accounting',\n",
       "       'AdHoc', 'Addictions', 'Aerospace_and_Defense', 'Agriculture',\n",
       "       'Agriculture_and_Forestry', 'Alternative', 'Animal',\n",
       "       'ArchitectureEducation', 'Artificial_Intelligence',\n",
       "       'ArtificiallIntelligence', 'Arts_and_Entertainment', 'Astronomy',\n",
       "       'Automotive', 'Bands', 'Baseball', 'Basketball', 'BioMedical',\n",
       "       'Biology', 'Biotechnology_and_Pharmaceuticals', 'Bowling',\n",
       "       'Business_Services', 'CAD_and_CAM', 'Chemicals', 'Chemistry',\n",
       "       'CommunicationSystems', 'Companies', 'ComputationalGeometry',\n",
       "       'Computer_Science', 'Conditions_and_Diseases',\n",
       "       'Construction_and_Maintenance', 'Consultants',\n",
       "       'Consumer_Goods_and_Services', 'Cricket', 'Cycling',\n",
       "       'DataManagement', 'DataMining', 'Data_Communications',\n",
       "       'Data_Formats', 'DatabaseSystems', 'DeclarativeProgramming',\n",
       "       'DistributedSimulation', 'E-Commerce', 'Earth_Sciences',\n",
       "       'Education', 'Education_and_Training',\n",
       "       'Electronics_and_Electrical', 'EletronicSociety',\n",
       "       'EmbeddedInteraction', 'EmbeddedNetworked', 'EmbeddedSystems',\n",
       "       'Employment', 'Energy', 'Entertainment', 'Environment',\n",
       "       'Equestrian', 'Fencing', 'Financial', 'Financial_Services',\n",
       "       'Flying_Discs', 'Food_and_Related_Products', 'Football', 'Foreign',\n",
       "       'Goats', 'Golf', 'Graphics', 'Gymnastics', 'Hardware',\n",
       "       'Healthcare', 'Hockey', 'Hospitality', 'Human_Resources',\n",
       "       'HypertextHypermedia', 'IEEVis', 'Industrial_Goods_and_Services',\n",
       "       'InformationRetrieval', 'Information_Technology',\n",
       "       'Instruments_and_Supplies', 'International_Business_and_Trade',\n",
       "       'Internet', 'Investing', 'Lacrosse', 'Management',\n",
       "       'ManagementData', 'Marketing_and_Advertising', 'Martial_Arts',\n",
       "       'Materials', 'Math', 'Medicine', 'Mental_Health', 'Metro',\n",
       "       'Microarchitecture', 'Mining_and_Drilling', 'MobileMultimedia',\n",
       "       'MobileSystems', 'Mobile_Computing', 'ModelsTechnologies',\n",
       "       'MolecularBiology', 'Motorsports', 'Multimedia', 'National',\n",
       "       'Nursing', 'Nutrition', 'Open_Source', 'Opportunities',\n",
       "       'Paintball', 'ParallelAlgorithms', 'ParallelProgramming',\n",
       "       'Pharmacy', 'PhysicalModeling', 'Physics', 'Professions',\n",
       "       'Programming', 'Public_Health_and_Safety',\n",
       "       'Publishing_and_Printing', 'RationalityKnowledge', 'Real_Estate',\n",
       "       'Reproductive_Health', 'Retail_Trade', 'Robotics', 'Running',\n",
       "       'Science_in_Society', 'Security', 'Senior_Health', 'Sheep',\n",
       "       'SimulationConference', 'Skating', 'Small_Business', 'Soccer',\n",
       "       'Social_Sciences', 'Softball', 'Software', 'SoftwareEng',\n",
       "       'SoftwarePerformance', 'SoftwareReusability', 'SoftwareTechnology',\n",
       "       'Sports', 'Strength_Sports', 'SystemDesign', 'SystemSupportGames',\n",
       "       'Systems', 'Technology', 'TechnologyEducation',\n",
       "       'Telecommunications', 'Tennis', 'Textiles_and_Nonwovens', 'Theory',\n",
       "       'TheoryComputing', 'Track_and_Field',\n",
       "       'Transportation_and_Logistics', 'VirtualREality', 'Volleyball',\n",
       "       'VolumeVisualization', 'Water_Sports', 'WebAccessibility',\n",
       "       'WebIntelligence', 'Winter_Sports', 'Wrestling', '_americas',\n",
       "       '_americas_esvl', '_americas_mrha_ooc',\n",
       "       'accuracy_garmin_nuvi_255W_gps', 'acq', 'alt_atheism', 'alum',\n",
       "       'art', 'austdlr', 'barley', 'basic_materials',\n",
       "       'bathroom_bestwestern_hotel_sfo', 'battery-life_amazon_kindle',\n",
       "       'battery-life_ipod_nano_8gb', 'battery-life_netbook_1005ha', 'bfr',\n",
       "       'bill_williams_iii', 'bladder', 'bop', 'breast', 'business',\n",
       "       'buttons_amazon_kindle', 'c', 'c_mangmt_group_management',\n",
       "       'c_technote_mail_projects', 'cable', 'cacm', 'california', 'can',\n",
       "       'capital_goods', 'carcass', 'castor-oil', 'castorseed', 'ces',\n",
       "       'cisi', 'citruspulp', 'cocoa', 'coconut', 'coconut-oil', 'coffee',\n",
       "       'colon', 'comfort_honda_accord_2008', 'comfort_toyota_camry_2007',\n",
       "       'comp_graphics', 'comp_os_ms-windows_misc',\n",
       "       'comp_sys_ibm_pc_hardware', 'comp_sys_mac_hardware',\n",
       "       'comp_windows_x', 'computer', 'conglomerates_industry',\n",
       "       'consumer_cyclical', 'consumer_non-cyclical', 'copper',\n",
       "       'copra-cake', 'corn', 'corn-oil', 'cornglutenfeed', 'corporate',\n",
       "       'cotton', 'cotton-oil', 'cottonseed', 'cpi', 'cpu', 'cran',\n",
       "       'crude', 'cruzado', 'culture', 'data_management',\n",
       "       'deal_communication', 'dfl', 'directions_garmin_nuvi_255W_gps',\n",
       "       'display_garmin_nuvi_255W_gps', 'dkr', 'dlr', 'dmk', 'earn',\n",
       "       'ecology', 'economics', 'electronics', 'endometrial', 'energy',\n",
       "       'entertainment', 'eyesight-issues_amazon_kindle', 'f-cattle',\n",
       "       'features_windows7', 'film', 'financial', 'fishmeal',\n",
       "       'fonts_amazon_kindle', 'food', 'food_holiday_inn_london',\n",
       "       'food_swissotel_chicago', 'foreign', 'free_bestwestern_hotel_sfo',\n",
       "       'fuel', 'gas', 'gas_mileage_toyota_camry_2007', 'genco_jv_ipo',\n",
       "       'geophysics', 'gnp', 'gold', 'grain', 'gravitional_theory',\n",
       "       'groundnut', 'groundnut-oil', 'ham', 'health', 'healthcare',\n",
       "       'heat', 'hk', 'hog', 'housing', 'hydro', 'income', 'industry',\n",
       "       'instal-debt', 'interest', 'interior_honda_accord_2008',\n",
       "       'interior_toyota_camry_2007', 'inventories', 'ipi', 'iron-steel',\n",
       "       'irrelevant', 'iso__pricecaps', 'jet', 'jobs',\n",
       "       'keyboard_netbook_1005ha', 'kidney', 'l-cattle', 'lead', 'lei',\n",
       "       'leukemia', 'lin-meal', 'lin-oil', 'linseed', 'lit', 'livestock',\n",
       "       'location_bestwestern_hotel_sfo', 'location_holiday_inn_london',\n",
       "       'logistics', 'lumber', 'lung', 'math', 'meal-feed', 'med', 'media',\n",
       "       'medical', 'meetings', 'melanoma', 'metals', 'metro',\n",
       "       'mileage_honda_accord_2008', 'misc_forsale', 'money', 'money-fx',\n",
       "       'money-supply', 'movie', 'multimedia', 'music', 'naphtha',\n",
       "       'nat-gas', 'national', 'navigation_amazon_kindle', 'negative',\n",
       "       'networking', 'neuroscience', 'nickel', 'nkr',\n",
       "       'non_hodgkin_lymphoma', 'nzdlr', 'oat', 'oceanography', 'oilseed',\n",
       "       'online', 'online_trading', 'orange', 'palladium', 'palm-oil',\n",
       "       'palmkernel', 'pancreatic', 'parking_bestwestern_hotel_sfo',\n",
       "       'people', 'performance_honda_accord_2008',\n",
       "       'performance_netbook_1005ha', 'peseta', 'pet-chem', 'platinum',\n",
       "       'plywood', 'politic', 'politics', 'pork-belly', 'positive',\n",
       "       'potato', 'price_amazon_kindle', 'price_holiday_inn_london',\n",
       "       'propane', 'prostate', 'quality_toyota_camry_2007', 'radio',\n",
       "       'rand', 'rape-meal', 'rape-oil', 'rapeseed', 'rec_autos',\n",
       "       'rec_motorcycles', 'rec_sport_baseball', 'rec_sport_hockey',\n",
       "       'red-bean', 'research', 'reserves', 'restaurant', 'retail',\n",
       "       'review', 'rice', 'ringgit', 'room_holiday_inn_london',\n",
       "       'rooms_bestwestern_hotel_sfo', 'rooms_swissotel_chicago', 'rubber',\n",
       "       'rupiah', 'rye', 'satellite_garmin_nuvi_255W_gps', 'saudriyal',\n",
       "       'sci_crypt', 'sci_electronics', 'sci_med', 'sci_space',\n",
       "       'screen_garmin_nuvi_255W_gps', 'screen_ipod_nano_8gb',\n",
       "       'screen_netbook_1005ha', 'seats_honda_accord_2008',\n",
       "       'service_bestwestern_hotel_sfo', 'service_holiday_inn_london',\n",
       "       'service_swissotel_hotel_chicago', 'services', 'sfr', 'ship',\n",
       "       'silver', 'size_asus_netbook_1005ha', 'skr',\n",
       "       'soc_religion_christian', 'sociology', 'software_engineering',\n",
       "       'sorghum', 'sound_ipod_nano_8gb', 'soy-meal', 'soy-oil', 'soybean',\n",
       "       'spam', 'speed_garmin_nuvi_255W_gps', 'speed_windows7', 'sports',\n",
       "       'staff_bestwestern_hotel_sfo', 'staff_swissotel_chicago', 'stage',\n",
       "       'statistics', 'stg', 'strategic-metal', 'sugar', 'sun-meal',\n",
       "       'sun-oil', 'sunseed', 'talk_politic_guns', 'talk_politics_mideast',\n",
       "       'talk_politics_misc', 'talk_religion_misc', 'tapioca', 'tea',\n",
       "       'tech', 'technology', 'television', 'theory_computing', 'thyroid',\n",
       "       'tin', 'trade', 'transmission_toyota_camry_2007', 'transportation',\n",
       "       'tufco', 'tw_commercial_group', 'universities',\n",
       "       'updates_garmin_nuvi_255W_gps', 'utilities', 'variety', 'veg-oil',\n",
       "       'video_ipod_nano_8gb', 'voice_garmin_nuvi_255W_gps', 'wellhead',\n",
       "       'wheat', 'wool', 'wpi', 'yen', 'zinc'], dtype=object)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "le.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(df['tokens'], Y, test_size=0.2, random_state=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('vectorizer', TfidfVectorizer()), ('clf', LinearSVC())]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('vectorizer', TfidfVectorizer()),\n",
    "    ('clf', LinearSVC())\n",
    "])\n",
    "pipeline.steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline.fit(df['tokens'], Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 3, 1, 1, 0, 1, 1, 0, 0,\n",
       "       2, 2, 0, 2, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 3,\n",
       "       0, 0, 0, 0, 1, 0, 2, 0, 0, 1, 0, 0, 1, 0, 1, 0])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = pipeline.predict(x_test)\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 3, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 3, 1, 1, 0, 1, 1, 1, 0,\n",
       "       2, 2, 0, 2, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 3, 2, 0, 3,\n",
       "       0, 0, 0, 0, 1, 1, 2, 0, 0, 1, 0, 0, 1, 0, 1, 0])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8166666666666667"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         precision    recall  f1-score   support\n",
      "\n",
      "ArtificiallIntelligence       0.69      1.00      0.82        25\n",
      "               Robotics       1.00      0.65      0.79        26\n",
      "                Systems       1.00      0.80      0.89         5\n",
      "                 Theory       1.00      0.75      0.86         4\n",
      "\n",
      "               accuracy                           0.82        60\n",
      "              macro avg       0.92      0.80      0.84        60\n",
      "           weighted avg       0.87      0.82      0.82        60\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, pred, target_names=le.classes_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#algo sobre artificial intelligence\n",
    "text = ['sdsdsdsds'] \n",
    "pred = pipeline.predict(text)\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_dbscan",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
