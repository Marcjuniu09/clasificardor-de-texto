{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\marcj\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\marcj\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\marcj\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "C:\\Users\\marcj\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import zipfile\n",
    "import os\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.pipeline import Pipeline\n",
    "from time import sleep\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "import requests\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import urllib\n",
    "from urllib.request import urlretrieve \n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "\n",
    "import zipfile\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from sklearn.model_selection import ParameterGrid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>subject manner similar termin graphic graphic ...</td>\n",
       "      <td>comp_windows_x</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>standard cost offic subject name count bruce v...</td>\n",
       "      <td>comp_windows_x</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>subject nasa nasa nasa nasa outland voic toolk...</td>\n",
       "      <td>comp_windows_x</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>info subject server share friend friend close ...</td>\n",
       "      <td>comp_windows_x</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>advantag helen helen code support subject citi...</td>\n",
       "      <td>comp_windows_x</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18823</th>\n",
       "      <td>investor ga ga presid vo standard subject enfo...</td>\n",
       "      <td>talk_politic_guns</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18824</th>\n",
       "      <td>analysi ga ga ga ga ga laughabl beryllium bery...</td>\n",
       "      <td>talk_politic_guns</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18825</th>\n",
       "      <td>na info quot illinoi illinoi illinoi illinoi s...</td>\n",
       "      <td>talk_politic_guns</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18826</th>\n",
       "      <td>sacrific cold subject ccwf ccwf mikei mikei ut...</td>\n",
       "      <td>talk_politic_guns</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18827</th>\n",
       "      <td>di subject antigun citizen unreason rkba milli...</td>\n",
       "      <td>talk_politic_guns</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18828 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    Text              Class\n",
       "0      subject manner similar termin graphic graphic ...     comp_windows_x\n",
       "1      standard cost offic subject name count bruce v...     comp_windows_x\n",
       "2      subject nasa nasa nasa nasa outland voic toolk...     comp_windows_x\n",
       "3      info subject server share friend friend close ...     comp_windows_x\n",
       "4      advantag helen helen code support subject citi...     comp_windows_x\n",
       "...                                                  ...                ...\n",
       "18823  investor ga ga presid vo standard subject enfo...  talk_politic_guns\n",
       "18824  analysi ga ga ga ga ga laughabl beryllium bery...  talk_politic_guns\n",
       "18825  na info quot illinoi illinoi illinoi illinoi s...  talk_politic_guns\n",
       "18826  sacrific cold subject ccwf ccwf mikei mikei ut...  talk_politic_guns\n",
       "18827  di subject antigun citizen unreason rkba milli...  talk_politic_guns\n",
       "\n",
       "[18828 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('data/20ng.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aplicar_tfidf_em_dados(dados):\n",
    "    # Extrair as colunas de texto, classes e tokens\n",
    "    texto = dados['text']\n",
    "    classes = dados['Class']\n",
    "    tokens = dados['tokens']\n",
    "\n",
    "    # Inicializar o TfidfVectorizer\n",
    "    tfidf_vectorizer = TfidfVectorizer()\n",
    "\n",
    "    # Aplicar o vetorizador ao texto\n",
    "    tfidf_matrix = tfidf_vectorizer.fit_transform(texto)\n",
    "\n",
    "    # Transformar as classes em valores numéricos usando LabelEncoder\n",
    "    label_encoder = LabelEncoder()\n",
    "    classes_encoded = label_encoder.fit_transform(classes)\n",
    "\n",
    "    # Criar um DataFrame para armazenar os resultados\n",
    "    resultado = pd.DataFrame(tfidf_matrix.toarray(), columns=tfidf_vectorizer.get_feature_names_out())\n",
    "\n",
    "    # Adicionar coluna de classes ao DataFrame de resultados\n",
    "    resultado['classes'] = classes_encoded\n",
    "\n",
    "    return resultado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(df['Text'], df['Class'], test_size=0.2, random_state=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vec = TfidfVectorizer(stop_words='english', max_df=0.7)\n",
    "tfidf_train = tfidf_vec.fit_transform(x_train)\n",
    "tfidf_test = tfidf_vec.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:   0.889\n",
      "[[134   0   0   0   0   0   0   0   0   0   0   1   0   0   0  17   0   1\n",
      "    0   0]\n",
      " [  0 165  10  14   4   5   1   0   0   1   0   4   0   1   2   0   1   0\n",
      "    0   0]\n",
      " [  0   2 165  20   2   8   2   2   0   0   0   3   0   0   3   1   0   0\n",
      "    0   0]\n",
      " [  0   3   7 166  12   0   4   0   1   0   0   1   3   0   0   0   0   0\n",
      "    0   0]\n",
      " [  0   2   2   7 159   0   2   0   1   0   0   1   3   0   1   0   0   0\n",
      "    0   0]\n",
      " [  0   5   6   3   1 173   1   0   0   1   1   1   0   0   4   0   0   1\n",
      "    0   0]\n",
      " [  0   0   1  10   3   1 155   7   3   0   0   0   2   0   0   0   1   0\n",
      "    1   0]\n",
      " [  0   0   0   0   0   1   2 171   5   1   1   0   1   1   0   0   3   0\n",
      "    0   0]\n",
      " [  0   0   0   0   0   0   1   1 178   0   0   1   0   0   1   0   0   0\n",
      "    0   0]\n",
      " [  0   0   0   0   0   0   1   1   0 184   8   0   0   0   0   2   0   0\n",
      "    0   0]\n",
      " [  0   0   1   0   0   0   0   0   0   1 205   0   0   0   1   0   1   0\n",
      "    0   0]\n",
      " [  0   1   1   0   0   2   0   0   0   0   0 194   1   0   0   0   1   1\n",
      "    0   0]\n",
      " [  0   0   1   9   1   0   0   2   0   0   1   6 165   0   4   1   0   1\n",
      "    0   0]\n",
      " [  1   0   0   0   1   1   0   0   0   0   0   1   0 200   0   1   1   0\n",
      "    0   0]\n",
      " [  0   1   0   0   0   0   0   0   0   1   0   0   0   0 190   1   2   1\n",
      "    0   0]\n",
      " [  2   0   0   0   0   0   1   0   0   0   1   0   0   0   0 206   1   0\n",
      "    0   0]\n",
      " [  1   0   0   0   0   0   0   0   1   0   0   2   0   0   0   1 185   0\n",
      "    3   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   6   0 201\n",
      "    0   0]\n",
      " [  0   0   0   0   0   0   0   0   1   0   0   3   0   0   1   3  17   4\n",
      "  108   0]\n",
      " [ 17   1   1   0   0   0   0   0   2   1   0   0   0   0   1  42  13   0\n",
      "    3  44]]\n"
     ]
    }
   ],
   "source": [
    "clf = MultinomialNB()\n",
    "clf.fit(tfidf_train, y_train)\n",
    "pred = clf.predict(tfidf_test)\n",
    "score = accuracy_score(y_test, pred)\n",
    "print(\"accuracy:   %0.3f\" % score)\n",
    "cm = metrics.confusion_matrix(y_test, pred)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          precision    recall  f1-score   support\n",
      "\n",
      "             alt_atheism       0.86      0.88      0.87       153\n",
      "           comp_graphics       0.92      0.79      0.85       208\n",
      " comp_os_ms-windows_misc       0.85      0.79      0.82       208\n",
      "comp_sys_ibm_pc_hardware       0.72      0.84      0.78       197\n",
      "   comp_sys_mac_hardware       0.87      0.89      0.88       178\n",
      "          comp_windows_x       0.91      0.88      0.89       197\n",
      "            misc_forsale       0.91      0.84      0.88       184\n",
      "               rec_autos       0.93      0.92      0.92       186\n",
      "         rec_motorcycles       0.93      0.98      0.95       182\n",
      "      rec_sport_baseball       0.97      0.94      0.95       196\n",
      "        rec_sport_hockey       0.94      0.98      0.96       209\n",
      "               sci_crypt       0.89      0.97      0.93       201\n",
      "         sci_electronics       0.94      0.86      0.90       191\n",
      "                 sci_med       0.99      0.97      0.98       206\n",
      "               sci_space       0.91      0.97      0.94       196\n",
      "  soc_religion_christian       0.73      0.98      0.84       211\n",
      "       talk_politic_guns       0.82      0.96      0.88       193\n",
      "   talk_politics_mideast       0.96      0.97      0.96       208\n",
      "      talk_politics_misc       0.94      0.79      0.86       137\n",
      "      talk_religion_misc       1.00      0.35      0.52       125\n",
      "\n",
      "                accuracy                           0.89      3766\n",
      "               macro avg       0.90      0.88      0.88      3766\n",
      "            weighted avg       0.90      0.89      0.89      3766\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['talk_politic_guns'], dtype='<U24')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"i need a new gun\"\n",
    "text = [text]\n",
    "\n",
    "text_tfidf = tfidf_vec.transform(text)\n",
    "clf.predict(text_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\marcj\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\marcj\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\marcj\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "naive_bayes\n",
      "accuracy:   0.391\n",
      "-------------------------\n",
      "knn\n",
      "accuracy:   0.446\n",
      "-------------------------\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import zipfile\n",
    "import os\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.pipeline import Pipeline\n",
    "from time import sleep\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "import requests\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import urllib\n",
    "from urllib.request import urlretrieve \n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "\n",
    "import zipfile\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def train(df, model):\n",
    "    x_train, x_test, y_train, y_test = train_test_split(df['Text'], df['Class'], test_size=0.2, random_state=5)\n",
    "    tfidf_vec = TfidfVectorizer(stop_words='english', max_df=0.7)\n",
    "    tfidf_train = tfidf_vec.fit_transform(x_train)\n",
    "    tfidf_test = tfidf_vec.transform(x_test)\n",
    "    if model == 'naive_bayes':\n",
    "        clf = MultinomialNB()\n",
    "        clf.fit(tfidf_train, y_train)\n",
    "        pred = clf.predict(tfidf_test)\n",
    "\n",
    "    elif model == 'knn':\n",
    "        knn = KNeighborsClassifier(n_neighbors=5)\n",
    "        knn.fit(tfidf_train, y_train)\n",
    "        pred = knn.predict(tfidf_test)\n",
    "\n",
    "    score = accuracy_score(y_test, pred)\n",
    "        \n",
    "    return (\"accuracy:   %0.3f\" % score)\n",
    "\n",
    "\n",
    "def main():\n",
    "    list_models = ['naive_bayes', 'knn']\n",
    "    df = pd.read_parquet('data/df.parquet')\n",
    "    for model in list_models:\n",
    "        print(model)\n",
    "        print(train(df, model))\n",
    "        print('-------------------------')\n",
    "        \n",
    "        \n",
    "if __name__ == '__main__':  \n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
